{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/P19_48_72_images/results_filt/72hrs/aorta03'\n",
    "duration = '72hr'\n",
    "aorta = 'aorta03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate L2-distance from singletons to other cluster, other cluster sizes to other cluster and L2-distance between cells within a EdU cluster\n",
    "\n",
    "singletonDistances = []\n",
    "withinClusterDistances = []\n",
    "betweenClusterDistances = []\n",
    "\n",
    "os.chdir(path)\n",
    "files = [f for f in listdir(path) if isfile(join(path, f)) if \".DS_Store\" not in f if \".csv\" in f if \"._\" not in f]\n",
    "for file in files:\n",
    "\n",
    "    ###Singletons\n",
    "    ### Calculation of distances for singletons\n",
    "    df_help = pd.read_csv(join(path, file))\n",
    "    # get cluster sizes and how often they appear\n",
    "    unique, counts = np.unique(df_help['centroid'], return_counts=True)\n",
    "    #define singletons as cluster size of 1\n",
    "    singletons = unique[counts == 1]\n",
    "    for s in singletons:\n",
    "        # Get the coordinates of the singleton\n",
    "        xSingleton = df_help.loc[df_help['centroid'] == s]['X'].values[0]\n",
    "        ySingleton = df_help.loc[df_help['centroid'] == s]['Y'].values[0]\n",
    "        # define all other clusters as df_other\n",
    "        df_other = df_help.loc[df_help['centroid'] != s]\n",
    "        xother = df_other['X'].values\n",
    "        yother = df_other['Y'].values\n",
    "        points = np.column_stack((xother, yother))\n",
    "        # Calculate L2 distances from the singleton to all other clusters\n",
    "        distancesSingleton = np.linalg.norm(points - [xSingleton,ySingleton], axis=1)\n",
    "        singletonDistances.append(distancesSingleton[np.argmin(distancesSingleton)])\n",
    "\n",
    "    ### distances between all cluster \n",
    "    higher = unique[counts != 1]\n",
    "    for h in higher:\n",
    "        # get centroid of singletons cluster\n",
    "        xvalsCluster = df_help.loc[df_help['centroid'] == h]['X'].values\n",
    "        yvalsCluster = df_help.loc[df_help['centroid'] == h]['Y'].values\n",
    "        pointsCluster = np.column_stack((xvalsCluster, yvalsCluster))\n",
    "        df_other = df_help.loc[df_help['centroid'] != h]\n",
    "        if len(df_other != 0):\n",
    "            xother = df_other['X'].values\n",
    "            yother = df_other['Y'].values\n",
    "            pointsOther = np.column_stack((xother, yother))\n",
    "            minClusterDistance = 9999999999\n",
    "            for i, point in enumerate(pointsCluster):\n",
    "                # Calculate L2 distances from between clusters\n",
    "                distancesPoint = np.linalg.norm(pointsOther - point, axis=1)\n",
    "                if minClusterDistance > np.min(distancesPoint[distancesPoint > 0]):\n",
    "                    minClusterDistance = np.min(distancesPoint[distancesPoint > 0])\n",
    "            betweenClusterDistances.append(minClusterDistance)\n",
    "\n",
    "    ### Wwithin-cluster distances (only take clusters above one, because I need to calculate distance between nuclei within a cluster)\n",
    "    #needed for normalization\n",
    "    dfBiggerCluster = df_help[~df_help['centroid'].isin(singletons)]\n",
    "    min_distances = []\n",
    "    for i in np.unique(dfBiggerCluster['centroid']):\n",
    "        dfCluster = df_help.loc[df_help['centroid'] == i]\n",
    "        xCluster = dfCluster['X'].values\n",
    "        yCluster = dfCluster['Y'].values\n",
    "        points = np.column_stack((xCluster, yCluster))\n",
    "        # Calculate minimum distance to other points in the same cluster\n",
    "        for i, point in enumerate(points):\n",
    "            distances = np.linalg.norm(points - point, axis=1)\n",
    "            # Append the minimum distance that is greater than zero\n",
    "            withinClusterDistances.append(np.min(distances[distances > 0]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "normalizedSingleton = singletonDistances/np.mean(withinClusterDistances)\n",
    "normalizedWithinCluster = withinClusterDistances/np.mean(withinClusterDistances)\n",
    "normalizedBetweenCluster = betweenClusterDistances/np.mean(withinClusterDistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "df_singleton = pd.DataFrame({'duration': duration, 'aorta': aorta, 'type': 'singleton', 'normalizedDistance': normalizedSingleton})\n",
    "df_withinCluster = pd.DataFrame({'duration': duration, 'aorta': aorta, 'type': 'withinCluster', 'normalizedDistance': normalizedWithinCluster})\n",
    "df_betweenCluster = pd.DataFrame({'duration': duration, 'aorta': aorta, 'type': 'betweenCluster', 'normalizedDistance': normalizedBetweenCluster})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.concat([df_singleton, df_withinCluster, df_betweenCluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.to_csv('results/normalizedDistances_72hr_aorta03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### concat distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/normalizedDistances_72hr_aorta01.csv')\n",
    "df2 = pd.read_csv('results/normalizedDistances_72hr_aorta02.csv')\n",
    "df3 = pd.read_csv('results/normalizedDistances_72hr_aorta03.csv')\n",
    "\n",
    "dfAllAge = pd.concat([df1, df2, df3])\n",
    "dfAllAge.to_csv('results/normalizedDistances_72hr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
