{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choices, seed\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clusterPath = '/Users/jones/Downloads/resultsClusterSizesALLAllAges.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfAll = pd.read_csv(clusterPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def twoNucInCell(row):\n",
    "    return np.min([row['ki67'], row['clusterSize']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfAll['ki67Adjust'] = dfAll.apply(lambda row: twoNucInCell(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(a, b):\n",
    "    a = np.asarray(a, dtype=np.float)\n",
    "    b = np.asarray(b, dtype=np.float)\n",
    "\n",
    "    return np.sum(np.where(a != 0, a * np.log(a / b), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = \"1-21\"\n",
    "df = dfAll.loc[(dfAll.age == age)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActive = df.groupby('clusterSize').sum()\n",
    "dfActive = dfActive.reset_index(drop=False)\n",
    "dfActive['percentage'] = dfActive['ki67Adjust']/np.sum(dfActive['ki67Adjust'])\n",
    "for index, row in dfActive.iterrows():\n",
    "    if index == 0:\n",
    "        activeCellClustersReal = np.full(int(row['ki67Adjust']), int(row['clusterSize']))\n",
    "    else:\n",
    "        activeCellClustersReal = np.concatenate((activeCellClustersReal, np.full(int(row['ki67Adjust']), int(row['clusterSize']))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume `df.clusterSize` contains your initial cluster sizes\n",
    "unique, counts = np.unique(df.clusterSize, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster needs to appear more than 10times; if you want to add this filter\n",
    "\n",
    "mask = counts >= 10\n",
    "unique = unique[mask]\n",
    "counts = counts[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for exponential weights; fill in zeros for empty clusters\n",
    "\n",
    "# 0-7: 9 insert\n",
    "#1-21: 14,15,16,18\n",
    "unique = np.insert(unique, 13, 14)\n",
    "counts = np.insert(counts, 13, 0)\n",
    "\n",
    "unique = np.insert(unique, 14, 15)\n",
    "counts = np.insert(counts, 14, 0)\n",
    "\n",
    "unique = np.insert(unique, 15, 16)\n",
    "counts = np.insert(counts, 15, 0)\n",
    "\n",
    "unique = np.insert(unique, 17, 18)\n",
    "counts = np.insert(counts, 17, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1234)  # Set seed for reproducibility\n",
    "\n",
    "maximumPerCluster = counts * unique\n",
    "\n",
    "# Exponential weights based on cluster size\n",
    "weights = np.exp(unique - 1)  # Exponential function prioritizing larger clusters\n",
    "weights /= weights.sum()  # Normalize weights to form a probability distribution\n",
    "\n",
    "# Placeholder to store results of each simulation\n",
    "resultsExp = []\n",
    "\n",
    "# Run simulations\n",
    "for i in range(1000):\n",
    "    # Initialize for each simulation\n",
    "    simulation_result = []\n",
    "    max_per_cluster = maximumPerCluster.copy()  # Reset max capacities for each simulation\n",
    "    current_unique = unique.copy()  # Copy unique array for dynamic adjustment\n",
    "    current_weights = weights.copy()  # Copy weights array for dynamic adjustment\n",
    "    \n",
    "    # Sample each proliferative cell individually\n",
    "    for _ in range(np.sum(df.ki67Adjust)):\n",
    "        # Choose a cluster based on current weights\n",
    "        selected_cluster = choices(current_unique, current_weights)[0]\n",
    "        index = np.where(current_unique == selected_cluster)[0][0]  # Find index in current arrays\n",
    "\n",
    "        # Add the chosen cluster to the result\n",
    "        simulation_result.append(selected_cluster)\n",
    "        max_per_cluster[index] -= 1  # Decrease capacity for this cluster\n",
    "\n",
    "        # Remove the cluster if its capacity is 0\n",
    "        if max_per_cluster[index] == 0:\n",
    "            current_unique = np.delete(current_unique, index)\n",
    "            current_weights = np.delete(current_weights, index)\n",
    "            max_per_cluster = np.delete(max_per_cluster, index)\n",
    "\n",
    "            # Re-normalize weights\n",
    "            current_weights /= current_weights.sum()\n",
    "\n",
    "    resultsExp.append(simulation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exponential function\n",
    "seedNumber = 1234*1\n",
    "random.seed(seedNumber)\n",
    "distanceRealWasserstein = []\n",
    "negControlWasserstein = []\n",
    "distanceJensenShannon = []\n",
    "negControlJensenShannon = []\n",
    "distanceKL = []\n",
    "negControlKL = []\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    distanceRealWasserstein.append(scipy.stats.wasserstein_distance(activeCellClustersReal, resultsExp[i]))\n",
    "\n",
    "    uniqueSample, countsSample = np.unique(resultsExp[i], return_counts=True)\n",
    "    percentageSimuli = []\n",
    "    for index, row  in dfActive.iterrows():\n",
    "        if len(countsSample[np.where(uniqueSample==row['clusterSize'])]) == 0:\n",
    "            percentageSimuli.append(sys.float_info.epsilon)\n",
    "        else:\n",
    "            percentageSimuli.append(countsSample[np.where(uniqueSample==row['clusterSize'])][0]/np.sum(df.ki67Adjust))\n",
    "    percentageSimuli = np.asarray(percentageSimuli)\n",
    "    distanceJensenShannon.append(scipy.spatial.distance.jensenshannon(dfActive['percentage'].values, percentageSimuli))\n",
    "    distanceKL.append(KL(dfActive['percentage'].values,percentageSimuli))\n",
    "    for j in range(i+1,1000):\n",
    "        negControlWasserstein.append(scipy.stats.wasserstein_distance(resultsExp[j], resultsExp[i]))\n",
    "        uniqueSample, countsSample = np.unique(resultsExp[j], return_counts=True)\n",
    "        percentageSimulj = []\n",
    "        for index, row  in dfActive.iterrows():\n",
    "            if len(countsSample[np.where(uniqueSample==row['clusterSize'])]) == 0:\n",
    "                percentageSimulj.append(sys.float_info.epsilon)\n",
    "            else:\n",
    "                percentageSimulj.append(countsSample[np.where(uniqueSample==row['clusterSize'])][0]/np.sum(df.ki67Adjust))\n",
    "        percentageSimulj = np.asarray(percentageSimulj)\n",
    "        negControlJensenShannon.append(scipy.spatial.distance.jensenshannon(percentageSimuli, percentageSimulj))\n",
    "        negControlKL.append(KL(percentageSimuli, percentageSimulj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realDist = pd.DataFrame({'age': age, 'simulation': 'ExpData', 'Wasserstein': distanceRealWasserstein, 'JensenShannon': distanceJensenShannon, 'KL': distanceKL})\n",
    "df_negControl= pd.DataFrame({'age': age, 'simulation': 'NegControl', 'Wasserstein': negControlWasserstein, 'JensenShannon': negControlJensenShannon, 'KL': negControlKL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realDist.to_csv(\"/Users/jones/Downloads/realDistance_ExponentialData_1-21.csv\", index = False)\n",
    "df_negControl.to_csv(\"/Users/jones/Downloads/negativeControl_ExponentialData_1-21.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in zeros for empty clusters\n",
    "# 0-7: 9 insert\n",
    "#1-21: 14,15,16,18\n",
    "\n",
    "unique, countsCl = np.unique(df.clusterSize, return_counts=True)\n",
    "unique = np.insert(unique, 13, 14)\n",
    "countsCl = np.insert(countsCl, 13, 0)\n",
    "\n",
    "unique = np.insert(unique, 14, 15)\n",
    "countsCl = np.insert(countsCl, 14, 0)\n",
    "\n",
    "unique = np.insert(unique, 15, 16)\n",
    "countsCl = np.insert(countsCl, 15, 0)\n",
    "\n",
    "unique = np.insert(unique, 17, 18)\n",
    "countsCl = np.insert(countsCl, 17, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/4p5g0w_j4jv11sr24nv1b0140000gn/T/ipykernel_43691/4152628166.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  a = np.asarray(a, dtype=np.float)\n",
      "/var/folders/6r/4p5g0w_j4jv11sr24nv1b0140000gn/T/ipykernel_43691/4152628166.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  b = np.asarray(b, dtype=np.float)\n",
      "/var/folders/6r/4p5g0w_j4jv11sr24nv1b0140000gn/T/ipykernel_43691/4152628166.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.where(a != 0, a * np.log(a / b), 0))\n",
      "/var/folders/6r/4p5g0w_j4jv11sr24nv1b0140000gn/T/ipykernel_43691/4152628166.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sum(np.where(a != 0, a * np.log(a / b), 0))\n"
     ]
    }
   ],
   "source": [
    "#Markovian divison\n",
    "seedNumber = 1234*1\n",
    "random.seed(seedNumber)\n",
    "distanceRealWasserstein = []\n",
    "negControlWasserstein = []\n",
    "distanceJensenShannon = []\n",
    "negControlJensenShannon = []\n",
    "distanceKL = []\n",
    "negControlKL = []\n",
    "dataCluster = []\n",
    "\n",
    "\n",
    "counts = countsCl * unique\n",
    "length = np.sum(counts)\n",
    "weights = counts/length\n",
    "\n",
    "for i in range(1000):\n",
    "    dataCluster.append(choices(unique,weights, k= np.sum(df.ki67Adjust)))\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    distanceRealWasserstein.append(scipy.stats.wasserstein_distance(activeCellClustersReal, dataCluster[i]))\n",
    "\n",
    "    uniqueSample, countsSample = np.unique(dataCluster[i], return_counts=True)\n",
    "    percentageSimuli = []\n",
    "    for index, row  in dfActive.iterrows():\n",
    "        if len(countsSample[np.where(uniqueSample==row['clusterSize'])]) == 0:\n",
    "            percentageSimuli.append(sys.float_info.epsilon)\n",
    "        else:\n",
    "            percentageSimuli.append(countsSample[np.where(uniqueSample==row['clusterSize'])][0]/np.sum(df.ki67Adjust))\n",
    "    percentageSimuli = np.asarray(percentageSimuli)\n",
    "    distanceJensenShannon.append(scipy.spatial.distance.jensenshannon(dfActive['percentage'].values, percentageSimuli))\n",
    "    distanceKL.append(KL(dfActive['percentage'].values,percentageSimuli))\n",
    "    for j in range(i+1,1000):\n",
    "        negControlWasserstein.append(scipy.stats.wasserstein_distance(dataCluster[j], dataCluster[i]))\n",
    "        uniqueSample, countsSample = np.unique(dataCluster[j], return_counts=True)\n",
    "        percentageSimulj = []\n",
    "        for index, row  in dfActive.iterrows():\n",
    "            if len(countsSample[np.where(uniqueSample==row['clusterSize'])]) == 0:\n",
    "                percentageSimulj.append(sys.float_info.epsilon)\n",
    "            else:\n",
    "                percentageSimulj.append(countsSample[np.where(uniqueSample==row['clusterSize'])][0]/np.sum(df.ki67Adjust))\n",
    "        percentageSimulj = np.asarray(percentageSimulj)\n",
    "        negControlJensenShannon.append(scipy.spatial.distance.jensenshannon(percentageSimuli, percentageSimulj))\n",
    "        negControlKL.append(KL(percentageSimuli, percentageSimulj))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realDist = pd.DataFrame({'age': age, 'simulation': 'ExpData', 'Wasserstein': distanceRealWasserstein, 'JensenShannon': distanceJensenShannon, 'KL': distanceKL})\n",
    "df_negControl= pd.DataFrame({'age': age, 'simulation': 'NegControl', 'Wasserstein': negControlWasserstein, 'JensenShannon': negControlJensenShannon, 'KL': negControlKL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realDist.to_csv('/Users/jones/Downloads/realDistance_MarkDiv_1-21.csv', index=False)\n",
    "df_negControl.to_csv('/Users/jones/Downloads/negativeControl_MarkDiv_1-21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to filter clusters, which appear more than 10 times\n",
    "unique, counts = np.unique(df.clusterSize, return_counts=True)\n",
    "mask = counts >= 10\n",
    "unique = unique[mask]\n",
    "counts = counts[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in zeros for empty clusters\n",
    "# 0-7: 9 insert\n",
    "#1-21: 14,15,16,18\n",
    "\n",
    "unique, counts = np.unique(df.clusterSize, return_counts=True)\n",
    "\n",
    "unique = np.insert(unique, 13, 14)\n",
    "counts = np.insert(counts, 13, 0)\n",
    "\n",
    "unique = np.insert(unique, 14, 15)\n",
    "counts = np.insert(counts, 14, 0)\n",
    "\n",
    "unique = np.insert(unique, 15, 16)\n",
    "counts = np.insert(counts, 15, 0)\n",
    "\n",
    "unique = np.insert(unique, 17, 18)\n",
    "counts = np.insert(counts, 17, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Markovian cluster\n",
    "seedNumber = 1234*2\n",
    "random.seed(seedNumber)\n",
    "distanceRealWasserstein = []\n",
    "negControlWasserstein = []\n",
    "distanceJensenShannon = []\n",
    "negControlJensenShannon = []\n",
    "distanceKL = []\n",
    "negControlKL = []\n",
    "dataCluster = []\n",
    "\n",
    "#unique, counts = np.unique(df.clusterSize, return_counts=True)\n",
    "weights = counts/np.sum(counts)\n",
    "dataCluster = []\n",
    "for i in range(1000):\n",
    "    dataCluster.append(choices(unique,weights, k= np.sum(df.ki67Adjust)))\n",
    "\n",
    "for i in range(1000):\n",
    "    distanceRealWasserstein.append(scipy.stats.wasserstein_distance(activeCellClustersReal, dataCluster[i]))\n",
    "\n",
    "    uniqueSample, countsSample = np.unique(dataCluster[i], return_counts=True)\n",
    "    percentageSimuli = []\n",
    "    for index, row  in dfActive.iterrows():\n",
    "        if len(countsSample[np.where(uniqueSample==row['clusterSize'])]) == 0:\n",
    "            percentageSimuli.append(sys.float_info.epsilon)\n",
    "        else:\n",
    "            percentageSimuli.append(countsSample[np.where(uniqueSample==row['clusterSize'])][0]/np.sum(df.ki67Adjust))\n",
    "    percentageSimuli = np.asarray(percentageSimuli)\n",
    "    distanceJensenShannon.append(scipy.spatial.distance.jensenshannon(dfActive['percentage'].values, percentageSimuli))\n",
    "    distanceKL.append(KL(dfActive['percentage'].values,percentageSimuli))\n",
    "    for j in range(i+1,1000):\n",
    "        negControlWasserstein.append(scipy.stats.wasserstein_distance(dataCluster[j], dataCluster[i]))\n",
    "        uniqueSample, countsSample = np.unique(dataCluster[j], return_counts=True)\n",
    "        percentageSimulj = []\n",
    "        for index, row  in dfActive.iterrows():\n",
    "            if len(countsSample[np.where(uniqueSample==row['clusterSize'])]) == 0:\n",
    "                percentageSimulj.append(sys.float_info.epsilon)\n",
    "            else:\n",
    "                percentageSimulj.append(countsSample[np.where(uniqueSample==row['clusterSize'])][0]/np.sum(df.ki67Adjust))\n",
    "        percentageSimulj = np.asarray(percentageSimulj)\n",
    "        negControlJensenShannon.append(scipy.spatial.distance.jensenshannon(percentageSimuli, percentageSimulj))\n",
    "        negControlKL.append(KL(percentageSimuli, percentageSimulj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realDist = pd.DataFrame({'age': age, 'simulation': 'ExpData', 'Wasserstein': distanceRealWasserstein, 'JensenShannon': distanceJensenShannon, 'KL': distanceKL})\n",
    "df_negControl= pd.DataFrame({'age': age, 'simulation': 'NegControl', 'Wasserstein': negControlWasserstein, 'JensenShannon': negControlJensenShannon, 'KL': negControlKL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realDist.to_csv('/Users/jones/Downloads/realDistance_MarkCl_1-21.csv', index=False)\n",
    "df_negControl.to_csv('/Users/jones/Downloads/negativeControl_MarkCl_1-21.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
